\chapter{Analysis}

% - 5-10 pages
% - case studies - how does it work in close to real-world settings
% - how well does it work (scale, speed, stability)

%%%%% start writing here

% - improvements to this orchestrator: deploy complete os, instead of only manipulating live-os
The currently described software architecture does not aim at a complete installation of an \gls{osacr} on a machine but instead uses the live-\gls{osacr} deployed during the information-gathering phase. Additional work is necessary to support not only the unattended installation of an \gls{osacr}, or even several different ones.

% - boot machines in batches, with an automatic batchsize that scales with the current machines network capacity. For single-initiation systems at least.
Another bottleneck of the current design is that all machines have to be booted to gather information on the underlying hardware. All machines are started simultaneously, producing one huge network traffic and power spike. In the test runs for the proof-of-concept implementations, this was not an issue, because the machines were only a few. In larger environments, including larger data centers, this approach is not an option. Therefore, the machines should be started in batches, where the batch size might scale with the current load of the issuing host (as the capacity hugely depends on the network bandwidth). Alternatively, a viable solution for bare-metal systems with no other orchestrator might be to provision machines dedicated for further the handling of \gls{dhcpacr}, \gls{tftpacr} and \gls{httpacr}. The number of these can then be scaled separately. While this could partially solve the network bottleneck, the power scaling problem persists nevertheless.

% - add integrations with external dhcp- tftp- http-servers.
The aforementioned dedicated services needed for provisioning are not necessarily fully managed and integrated into the described orchestrator. Interfaces for external systems like networking hardware should be implemented and integrated.

% - architecture improvements: plugin-system, so integrations (dhcp, tftp, http) are easier. Like terraform.
Even apart from these services, a plugin system similar to the one provided by Terraform would bring huge benefits. While \gls{toscaacr} has a similar feature with its imports, namespaces, and substitutions, the orchestrator itself needs additional capabilities as well. This includes the hardware extension described in this thesis, but also applies to the original \gls{toscaacr} standard as well: Currently limited to Bash and Python, plugins for additional implementation artifact languages are thinkable.

% - get a list of mac addresses directly from currently attached network cards. Broadcast/ARP?
The currently described provisioning workflow requires an initial list of MAC addresses. Further research should investigate whether retrieval of those addresses could be automated. A first idea would be a network broadcast, which leads to the addresses being communicated via the ARP protocol.

% - tosca standard improvements from notes. Example: Two types of script execution: one on the orchestrator and one on the nodes.
Apart from the implementation details on the tool itself, the \gls{toscaacr} standard or at least its specification has improvement potential as well. On several occasions, the \gls{yamlacr} examples provided along with the introduction of a new structure are invalid. The issues range from \gls{yamlacr}-structure errors, inconsistencies or simply missing information. The table in appendix A lists those in the order they occur in the specification. The Simple Profile extension has similar issues, those are listed in a similar table in appendix B.

% - recommendation for tosca standard: describe a reference orchestrator
The specification would also profit greatly from a detailed description of a reference orchestrator like the one by OpenTOSCA (which already is the semi-official reference implementation). That way, the tasks of the orchestrator would be clearer, some hidden design decisions in the standard would be at least described somewhere close and the development of such orchestrators would be significantly easier.
\newline\smallskip

% datacenter from scratch / initial deployment
% up-to-date tosca orchestrator, compliant with the original standard and Simple Profile -> IaC tool at least
Assuming a scenario where a new datacenter should be provisioned from scratch (no \gls{osacr} deployed), the tool described in this thesis can automate the initial setup. Because \gls{toscaacr} is the language of choice, and a compatible orchestrator is embedded in the application, users can make use of all capabilities the \gls{dslacr} provides. Since the original language can already be used for further provisioning and configuration management, the resulting application is a mixture of hardware provisioning, \gls{iacacr} provider, and -client.
\newline
% describe both physical and virtual infrastructure with the same language
The resulting application is not only another \gls{iacacr} tool with \gls{toscaacr} as its chosen language. It is also the first tool that can provision bare-metal machines on demand. And together with the hardware extension, it is one of the view tools, where description and deployment of virtual and physical infrastructure as code with the same language are possible.
\newline
% existing infrastructure
%   provisioning of new hardware is possible
%   migration to tosca necessary, but step by step possible
In a scenario where infrastructure is already deployed, and with a \gls{dslacr} different than \gls{toscaacr}, it is required to translate/migrate the codebase at least partially. But since \gls{toscaacr} allows integrations of other \gls{dslacr}s and tools, this can happen step by step. The same applies to existing infrastructure without any \gls{iacacr} codebase.
\newline\smallskip
% limitations
The included \gls{toscaacr} orchestrator fulfills all requirements described in the specifications of the standard and its Simple Profile extension. Because the hardware extension requires low-level access to some host capabilities (like listening on host port 67 and 68), the application needs to run with extended privileges.
\newline
The proposed bare-metal extension to \gls{toscaacr} brings the world close to \textquote{Jarvis, provide me a new cluster}.

% scaling: disk read speed (live-os image), network speed of root node
% speed: deploy without installation; available within a minute. deploy with installation; same amount plus os installation.
% stability: recovery feature to be done. example solution: ipmi for remote power-off

%TODO actual examples, how to implement a new node, how to implement a k8s cluster, how to implement a webserver

% what were the goals, what are the current capabilities
% how stable is it, what can it do in real world settings
% types, topology, tests
